{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Cl√©s disponibles dans artifacts : dict_keys(['scaler', 'model', 'metadata'])\n",
      "üîç Cl√©s disponibles dans metadata : dict_keys(['optimal_threshold', 'training_date', 'features', 'dtype_example', 'training_stats', 'performance_metrics', 'training_strategy'])\n",
      "‚úÖ Nombre de features : 85\n",
      "Extrait des features : ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_CREDIT', 'ANNUITY_INCOME_PERC']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "MODEL_PATH = \"../backend/models/lightgbm_production_artifact_20250415_081218.pkl\"\n",
    "\n",
    "# Chargement\n",
    "artifacts = joblib.load(MODEL_PATH)\n",
    "\n",
    "# Inspection des cl√©s principales\n",
    "print(\"üîç Cl√©s disponibles dans artifacts :\", artifacts.keys())\n",
    "\n",
    "# Si metadata est bien l√†, on regarde ce qu'il contient\n",
    "metadata = artifacts.get(\"metadata\", {})\n",
    "print(\"üîç Cl√©s disponibles dans metadata :\", metadata.keys())\n",
    "\n",
    "# On v√©rifie si les features sont bien d√©finies\n",
    "features = metadata.get(\"features\", None)\n",
    "if features is None:\n",
    "    print(\"‚ùå 'features' est manquant dans metadata.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Nombre de features : {len(features)}\")\n",
    "    print(\"Extrait des features :\", features[:5])  # Affiche les 5 premi√®res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Type des artifacts : <class 'numpy.ndarray'>\n",
      "üîç Extrait des artifacts : ['EXT_SOURCE_1' 'EXT_SOURCE_2' 'EXT_SOURCE_3' 'AMT_CREDIT'\n",
      " 'ANNUITY_INCOME_PERC']\n",
      "longueur du tableau 85\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Charge le fichier artifact contenant les informations\n",
    "artifact_path = \"../backend/models/lightgbm_production_artifact_20250415_081218.pkl\"\n",
    "\n",
    "# Charger les artifacts\n",
    "with open(artifact_path, 'rb') as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "# Afficher le type de l'objet charg√© pour mieux comprendre sa structure\n",
    "print(\"üîç Type des artifacts :\", type(artifacts))\n",
    "\n",
    "# Afficher un extrait des donn√©es pour comprendre la structure\n",
    "print(\"üîç Extrait des artifacts :\", artifacts[:5])  # Affiche les 5 premiers √©l√©ments si c'est un tableau\n",
    "print(\"longueur du tableau\" ,len(artifacts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Toutes les colonnes n√©cessaires sont pr√©sentes dans les donn√©es.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose que client_data est un DataFrame que tu veux pr√©dire\n",
    "TEST_SAMPLE_FOR_API = \"../backend/data/test_1000_sample_for_api.csv\"\n",
    "TEST_SAMPLE_WITH_TARGET = \"../backend/data/test_1000_sample_with_target.csv\"\n",
    "\n",
    "df_test = pd.read_csv(TEST_SAMPLE_WITH_TARGET)\n",
    "df_api = pd.read_csv(TEST_SAMPLE_FOR_API)\n",
    "\n",
    "client_id = df_test[\"SK_ID_CURR\"]\n",
    "client_data = df_api[df_api[\"SK_ID_CURR\"] == client_id].drop(columns=[\"SK_ID_CURR\"])\n",
    "\n",
    "# Comparer les features attendues avec les donn√©es d'entr√©e\n",
    "expected_features = artifacts\n",
    "\n",
    "# Trouver les colonnes manquantes dans les donn√©es d'entr√©e\n",
    "missing_cols = set(expected_features) - set(client_data.columns)\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "if missing_cols:\n",
    "    print(\"‚ö†Ô∏è Colonnes manquantes dans les donn√©es d'entr√©e :\", missing_cols)\n",
    "else:\n",
    "    print(\"‚úÖ Toutes les colonnes n√©cessaires sont pr√©sentes dans les donn√©es.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilit√© de d√©faut : 3.91%\n",
      "D√©cision : ‚úÖ Accept√©\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Charger les artefacts sauvegard√©s\n",
    "model_path = \"../backend/models/lightgbm_production_artifact_20250415_081218.pkl\"\n",
    "artifacts = joblib.load(model_path)\n",
    "\n",
    "# Extraire le mod√®le et le scaler\n",
    "model = artifacts['model']\n",
    "scaler = artifacts['scaler']\n",
    "\n",
    "# Si n√©cessaire, obtenir les m√©tadonn√©es\n",
    "metadata = artifacts['metadata']\n",
    "optimal_threshold = metadata['optimal_threshold']\n",
    "features = metadata['features']\n",
    "\n",
    "# V√©rifier les donn√©es d'entr√©e (client_data)\n",
    "client_data = client_data[features]  \n",
    "\n",
    "# Appliquer le scaler sur les donn√©es du client\n",
    "client_data_scaled = scaler.transform(client_data)\n",
    "\n",
    "# Appliquer le scaler en conservant les noms de colonnes\n",
    "client_data_scaled = pd.DataFrame(\n",
    "    scaler.transform(client_data),\n",
    "    columns=client_data.columns,\n",
    "    index=client_data.index\n",
    ")\n",
    "\n",
    "# Faire une pr√©diction sur les donn√©es du client\n",
    "pred_proba = model.predict_proba(client_data_scaled)[:, 1]  # Probabilit√© de d√©faut\n",
    "\n",
    "# Appliquer le seuil optimal pour la pr√©diction finale\n",
    "pred = (pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(f\"Probabilit√© de d√©faut : {pred_proba[0]:.2%}\")\n",
    "print(f\"D√©cision : {'üõë Refus√©' if pred[0] == 1 else '‚úÖ Accept√©'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Type des artifacts : <class 'numpy.ndarray'>\n",
      "üîç Forme des artifacts : (85,)\n",
      "üîç Extrait des artifacts : ['EXT_SOURCE_1' 'EXT_SOURCE_2' 'EXT_SOURCE_3' 'AMT_CREDIT'\n",
      " 'ANNUITY_INCOME_PERC']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Charge les artifacts depuis le fichier\n",
    "artifact_path = \"../backend/models/lightgbm_production_artifact_20250415_081218.pkl\"\n",
    "\n",
    "# Charger les artifacts\n",
    "with open(artifact_path, 'rb') as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "# V√©rifier la structure des artifacts\n",
    "print(\"üîç Type des artifacts :\", type(artifacts))\n",
    "print(\"üîç Forme des artifacts :\", artifacts.shape)  # V√©rifie si c'est un tableau NumPy et sa taille\n",
    "\n",
    "# Afficher un extrait pour mieux comprendre la structure\n",
    "print(\"üîç Extrait des artifacts :\", artifacts[:5])  # Affiche les 5 premiers √©l√©ments si c'est un tableau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es du client s√©lectionn√© :\n",
      "{'EXT_SOURCE_1': 0.5074440332442849, 'EXT_SOURCE_2': 0.7109608784019691, 'EXT_SOURCE_3': 0.7267112092725122, 'AMT_CREDIT': 1113840.0, 'ANNUITY_INCOME_PERC': 0.4222333333333333, 'BURO_DAYS_CREDIT_ENDDATE_MEAN': -65.0, 'BURO_DAYS_CREDIT_UPDATE_MEAN': -72.0, 'DAYS_BIRTH': -19274.0, 'DAYS_ID_PUBLISH': -2805.0, 'FLAG_EMP_PHONE': 1.0, 'NAME_INCOME_TYPE_PENSIONER': 0.0, 'BURO_AMT_CREDIT_SUM_MAX': 485640.0, 'BURO_CREDIT_ACTIVE_CLOSED_MEAN': 1.0, 'BURO_CREDIT_TYPE_CAR_LOAN_MEAN': 0.0, 'BURO_CREDIT_TYPE_CREDIT_CARD_MEAN': 0.0, 'BURO_CREDIT_TYPE_MICROLOAN_MEAN': 0.0, 'BURO_CREDIT_TYPE_MORTGAGE_MEAN': 0.0, 'BURO_DAYS_CREDIT_ENDDATE_MAX': -65.0, 'BURO_DAYS_CREDIT_MEAN': -1161.0, 'CODE_GENDER': 1.0, 'DAYS_EMPLOYED_PERC': 0.2647089343156584, 'DAYS_LAST_PHONE_CHANGE': -802.0, 'DAYS_REGISTRATION': -9316.0, 'DEF_60_CNT_SOCIAL_CIRCLE': 0.0, 'FLAG_DOCUMENT_3': 1.0, 'FLAG_DOCUMENT_6': 0.0, 'NAME_HOUSING_TYPE_RENTED_APARTMENT': 0.0, 'OCCUPATION_TYPE_ACCOUNTANTS': 0.0, 'ORGANIZATION_TYPE_BUSINESS_ENTITY_TYPE_3': 1.0, 'ORGANIZATION_TYPE_MILITARY': 0.0, 'ORGANIZATION_TYPE_SELF_EMPLOYED': 0.0, 'PAYMENT_RATE': 0.0511756625727213, 'REGION_POPULATION_RELATIVE': 0.04622, 'REGION_RATING_CLIENT_W_CITY': 1.0, 'REG_CITY_NOT_LIVE_CITY': 0.0, 'ACTIVE_DAYS_CREDIT_ENDDATE_MEAN': 716.0, 'AMT_REQ_CREDIT_BUREAU_QRT': 0.0, 'APPROVED_AMT_ANNUITY_MEAN': 12188.835, 'APPROVED_DAYS_DECISION_MIN': -802.0, 'APPROVED_HOUR_APPR_PROCESS_START_MEAN': 14.666666666666666, 'BURO_AMT_CREDIT_MAX_OVERDUE_MEAN': 0.0, 'BURO_AMT_CREDIT_SUM_DEBT_SUM': 0.0, 'BURO_CREDIT_TYPE_ANOTHER_TYPE_OF_LOAN_MEAN': 0.0, 'BURO_CREDIT_TYPE_LOAN_FOR_BUSINESS_DEVELOPMENT_MEAN': 0.0, 'BURO_CREDIT_TYPE_LOAN_FOR_THE_PURCHASE_OF_EQUIPMENT_MEAN': 0.0, 'BURO_DAYS_CREDIT_MAX': -1161.0, 'BURO_DAYS_CREDIT_VAR': 386627.0666666667, 'CLOSED_AMT_CREDIT_SUM_SUM': 485640.0, 'ELEVATORS_AVG': 0.0, 'FLAG_DOCUMENT_13': 0.0, 'FLAG_DOCUMENT_15': 0.0, 'FLAG_DOCUMENT_16': 0.0, 'FLAG_DOCUMENT_17': 0.0, 'FLAG_DOCUMENT_20': 0.0, 'FLAG_DOCUMENT_21': 0.0, 'FLAG_OWN_CAR': 0.0, 'FLAG_WORK_PHONE': 0.0, 'FLOORSMAX_MODE': 0.1667, 'INCOME_CREDIT_PERC': 0.12120232708468, 'INCOME_PER_PERSON': 67500.0, 'INSTAL_AMT_PAYMENT_MAX': 16267.815, 'INSTAL_AMT_PAYMENT_MEAN': 13673.899285714286, 'INSTAL_AMT_PAYMENT_MIN': 547.2, 'INSTAL_AMT_PAYMENT_SUM': 382869.18, 'INSTAL_DAYS_ENTRY_PAYMENT_MAX': -36.0, 'INSTAL_DAYS_ENTRY_PAYMENT_SUM': -10352.0, 'INSTAL_DBD_MAX': 29.0, 'INSTAL_DBD_MEAN': 4.928571428571429, 'INSTAL_DBD_SUM': 138.0, 'INSTAL_DPD_MEAN': 0.4285714285714285, 'INSTAL_PAYMENT_DIFF_MEAN': 514.0446428571429, 'INSTAL_PAYMENT_DIFF_SUM': 14393.25, 'LIVE_CITY_NOT_WORK_CITY': 0.0, 'LIVINGAREA_MODE': 0.0731, 'NAME_EDUCATION_TYPE_ACADEMIC_DEGREE': 0.0, 'NAME_EDUCATION_TYPE_SECONDARY__SECONDARY_SPECIAL': 1.0, 'NAME_FAMILY_STATUS_MARRIED': 1.0, 'NAME_HOUSING_TYPE_CO_OP_APARTMENT': 0.0, 'NAME_HOUSING_TYPE_MUNICIPAL_APARTMENT': 0.0, 'NAME_INCOME_TYPE_STUDENT': 0.0, 'NAME_INCOME_TYPE_WORKING': 0.0, 'NAME_TYPE_SUITE_OTHER_B': 0.0, 'OCCUPATION_TYPE_DRIVERS': 0.0, 'OCCUPATION_TYPE_LABORERS': 1.0, 'OCCUPATION_TYPE_LOW_SKILL_LABORERS': 0.0}\n",
      "R√©ponse de l'API :\n",
      "{\n",
      "    \"probability\": 2.69,\n",
      "    \"decision\": \"\\u2705 Accept\\u00e9\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "# URL de ton API (modifie selon ton environnement)\n",
    "API_URL = \"http://localhost:8000/predict\"\n",
    "\n",
    "# Chargement des donn√©es test\n",
    "df_test = pd.read_csv(\"../backend/data/test_1000_sample_for_api.csv\")\n",
    "\n",
    "# S√©lection al√©atoire d'un client\n",
    "random_client = df_test.sample(n=1)  # S√©lectionne un seul client au hasard\n",
    "client_data = random_client.drop(columns=[\"SK_ID_CURR\"]).to_dict(orient=\"records\")[0]  # Extrait les donn√©es du client sous forme de dictionnaire\n",
    "\n",
    "# Affichage des donn√©es du client s√©lectionn√©\n",
    "print(\"Donn√©es du client s√©lectionn√© :\")\n",
    "print(client_data)\n",
    "\n",
    "# Construction du corps de la requ√™te\n",
    "data = {\n",
    "    \"data\": client_data  # Les donn√©es du client s√©lectionn√©\n",
    "}\n",
    "\n",
    "# Envoi de la requ√™te √† l'API\n",
    "response = requests.post(API_URL, json=data)\n",
    "\n",
    "# Affichage de la r√©ponse de l'API\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"R√©ponse de l'API :\")\n",
    "    print(json.dumps(result, indent=4))\n",
    "else:\n",
    "    print(f\"Erreur {response.status_code} : {response.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'probability': 2.69, 'decision': '‚úÖ Accept√©'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "API_URL = \"http://localhost:8000/predict\"\n",
    "\n",
    "{\n",
    "  \"data\": {\n",
    "    \"EXT_SOURCE_1\": 0.5074440332442849,\n",
    "    \"EXT_SOURCE_2\": 0.7109608784019691,\n",
    "    \"EXT_SOURCE_3\": 0.7267112092725122,\n",
    "    \"AMT_CREDIT\": 1113840.0,\n",
    "    \"ANNUITY_INCOME_PERC\": 0.4222333333333333,\n",
    "    \"BURO_DAYS_CREDIT_ENDDATE_MEAN\": -65.0,\n",
    "    \"BURO_DAYS_CREDIT_UPDATE_MEAN\": -72.0,\n",
    "    \"DAYS_BIRTH\": -19274.0,\n",
    "    \"DAYS_ID_PUBLISH\": -2805.0,\n",
    "    \"FLAG_EMP_PHONE\": 1.0,\n",
    "    \"NAME_INCOME_TYPE_PENSIONER\": 0.0,\n",
    "    \"BURO_AMT_CREDIT_SUM_MAX\": 485640.0,\n",
    "    \"BURO_CREDIT_ACTIVE_CLOSED_MEAN\": 1.0,\n",
    "    \"BURO_CREDIT_TYPE_CAR_LOAN_MEAN\": 0.0,\n",
    "    \"BURO_CREDIT_TYPE_CREDIT_CARD_MEAN\": 0.0,\n",
    "    \"BURO_CREDIT_TYPE_MICROLOAN_MEAN\": 0.0,\n",
    "    \"BURO_CREDIT_TYPE_MORTGAGE_MEAN\": 0.0,\n",
    "    \"BURO_DAYS_CREDIT_ENDDATE_MAX\": -65.0,\n",
    "    \"BURO_DAYS_CREDIT_MEAN\": -1161.0,\n",
    "    \"CODE_GENDER\": 1.0,\n",
    "    \"DAYS_EMPLOYED_PERC\": 0.2647089343156584,\n",
    "    \"DAYS_LAST_PHONE_CHANGE\": -802.0,\n",
    "    \"DAYS_REGISTRATION\": -9316.0,\n",
    "    \"DEF_60_CNT_SOCIAL_CIRCLE\": 0.0,\n",
    "    \"FLAG_DOCUMENT_3\": 1.0,\n",
    "    \"FLAG_DOCUMENT_6\": 0.0,\n",
    "    \"NAME_HOUSING_TYPE_RENTED_APARTMENT\": 0.0,\n",
    "    \"OCCUPATION_TYPE_ACCOUNTANTS\": 0.0,\n",
    "    \"ORGANIZATION_TYPE_BUSINESS_ENTITY_TYPE_3\": 1.0,\n",
    "    \"ORGANIZATION_TYPE_MILITARY\": 0.0,\n",
    "    \"ORGANIZATION_TYPE_SELF_EMPLOYED\": 0.0,\n",
    "    \"PAYMENT_RATE\": 0.0511756625727213,\n",
    "    \"REGION_POPULATION_RELATIVE\": 0.04622,\n",
    "    \"REGION_RATING_CLIENT_W_CITY\": 1.0,\n",
    "    \"REG_CITY_NOT_LIVE_CITY\": 0.0,\n",
    "    \"ACTIVE_DAYS_CREDIT_ENDDATE_MEAN\": 716.0,\n",
    "    \"AMT_REQ_CREDIT_BUREAU_QRT\": 0.0,\n",
    "    \"APPROVED_AMT_ANNUITY_MEAN\": 12188.835,\n",
    "    \"APPROVED_DAYS_DECISION_MIN\": -802.0,\n",
    "    \"APPROVED_HOUR_APPR_PROCESS_START_MEAN\": 14.666666666666666,\n",
    "    \"BURO_AMT_CREDIT_MAX_OVERDUE_MEAN\": 0.0,\n",
    "    \"BURO_AMT_CREDIT_SUM_DEBT_SUM\": 0.0,\n",
    "    \"BURO_CREDIT_TYPE_ANOTHER_TYPE_OF_LOAN_MEAN\": 0.0,\n",
    "    \"BURO_CREDIT_TYPE_LOAN_FOR_BUSINESS_DEVELOPMENT_MEAN\": 0.0,\n",
    "    \"BURO_CREDIT_TYPE_LOAN_FOR_THE_PURCHASE_OF_EQUIPMENT_MEAN\": 0.0,\n",
    "    \"BURO_DAYS_CREDIT_MAX\": -1161.0,\n",
    "    \"BURO_DAYS_CREDIT_VAR\": 386627.0666666667,\n",
    "    \"CLOSED_AMT_CREDIT_SUM_SUM\": 485640.0,\n",
    "    \"ELEVATORS_AVG\": 0.0,\n",
    "    \"FLAG_DOCUMENT_13\": 0.0,\n",
    "    \"FLAG_DOCUMENT_15\": 0.0,\n",
    "    \"FLAG_DOCUMENT_16\": 0.0,\n",
    "    \"FLAG_DOCUMENT_17\": 0.0,\n",
    "    \"FLAG_DOCUMENT_20\": 0.0,\n",
    "    \"FLAG_DOCUMENT_21\": 0.0,\n",
    "    \"FLAG_OWN_CAR\": 0.0,\n",
    "    \"FLAG_WORK_PHONE\": 0.0,\n",
    "    \"FLOORSMAX_MODE\": 0.1667,\n",
    "    \"INCOME_CREDIT_PERC\": 0.12120232708468,\n",
    "    \"INCOME_PER_PERSON\": 67500.0,\n",
    "    \"INSTAL_AMT_PAYMENT_MAX\": 16267.815,\n",
    "    \"INSTAL_AMT_PAYMENT_MEAN\": 13673.899285714286,\n",
    "    \"INSTAL_AMT_PAYMENT_MIN\": 547.2,\n",
    "    \"INSTAL_AMT_PAYMENT_SUM\": 382869.18,\n",
    "    \"INSTAL_DAYS_ENTRY_PAYMENT_MAX\": -36.0,\n",
    "    \"INSTAL_DAYS_ENTRY_PAYMENT_SUM\": -10352.0,\n",
    "    \"INSTAL_DBD_MAX\": 29.0,\n",
    "    \"INSTAL_DBD_MEAN\": 4.928571428571429,\n",
    "    \"INSTAL_DBD_SUM\": 138.0,\n",
    "    \"INSTAL_DPD_MEAN\": 0.4285714285714285,\n",
    "    \"INSTAL_PAYMENT_DIFF_MEAN\": 514.0446428571429,\n",
    "    \"INSTAL_PAYMENT_DIFF_SUM\": 14393.25,\n",
    "    \"LIVE_CITY_NOT_WORK_CITY\": 0.0,\n",
    "    \"LIVINGAREA_MODE\": 0.0731,\n",
    "    \"NAME_EDUCATION_TYPE_ACADEMIC_DEGREE\": 0.0,\n",
    "    \"NAME_EDUCATION_TYPE_SECONDARY__SECONDARY_SPECIAL\": 1.0,\n",
    "    \"NAME_FAMILY_STATUS_MARRIED\": 1.0,\n",
    "    \"NAME_HOUSING_TYPE_CO_OP_APARTMENT\": 0.0,\n",
    "    \"NAME_HOUSING_TYPE_MUNICIPAL_APARTMENT\": 0.0,\n",
    "    \"NAME_INCOME_TYPE_STUDENT\": 0.0,\n",
    "    \"NAME_INCOME_TYPE_WORKING\": 0.0,\n",
    "    \"NAME_TYPE_SUITE_OTHER_B\": 0.0,\n",
    "    \"OCCUPATION_TYPE_DRIVERS\": 0.0,\n",
    "    \"OCCUPATION_TYPE_LABORERS\": 1.0,\n",
    "    \"OCCUPATION_TYPE_LOW_SKILL_LABORERS\": 0.0\n",
    "  }\n",
    "}\n",
    "\n",
    "response = requests.post(API_URL, json=data)\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import joblib\n",
    "import config\n",
    "from risk_gauge import show_risk_gauge, display_risk_message, animate_risk_gauge\n",
    "import numpy as np\n",
    "from st_aggrid import AgGrid\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "API_URL = \"http://localhost:8000\"\n",
    "ARTIFACT_PATH = \"../backend/models/lightgbm_production_artifact_20250415_081218.pkl\"\n",
    "THRESHOLD = 0.0931515  # Seuil de risque\n",
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"üè¶ Dashboard Cr√©dit - Pr√©dictions & Explicabilit√©\")\n",
    "\n",
    "# ===== Chargement des donn√©es =====\n",
    "@st.cache_data\n",
    "def load_test_data():\n",
    "    return pd.read_csv(\"../backend/data/test_2000_sample_for_api.csv\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model_artifacts():\n",
    "    artifacts = joblib.load(ARTIFACT_PATH)\n",
    "    model = artifacts['model']\n",
    "    scaler = artifacts['scaler']\n",
    "    features = artifacts['metadata']['features']\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    # Pr√©calcul des SHAP values globales (√©chantillonn√© pour plus de rapidit√©)\n",
    "    df_test_sample = df_test[features].sample(min(1000, len(df_test)), random_state=42)\n",
    "    df_test_sample_scaled = scaler.transform(df_test_sample)\n",
    "    global_shap_values = explainer.shap_values(df_test_sample_scaled)\n",
    "    \n",
    "    return model, scaler, features, explainer, global_shap_values, df_test_sample\n",
    "\n",
    "df_test = load_test_data()\n",
    "model, scaler, features, explainer, global_shap_values, df_test_sample = load_model_artifacts()\n",
    "#print(f\"Nombre de clients dans l'√©chantillon global : {len(df_test_sample)}\")\n",
    "#print(f\"Shape des SHAP values globales : {global_shap_values.shape}\")\n",
    "\n",
    "client_ids = df_test[\"SK_ID_CURR\"].unique().astype(int)\n",
    "\n",
    "# ===== Sidebar =====\n",
    "st.sidebar.markdown(\"## üîç Analyse d'un client\")\n",
    "selected_id = st.sidebar.selectbox(\"S√©lectionner un client\", client_ids)\n",
    "submitted = st.sidebar.button(\"Soumettre la pr√©diction\")\n",
    "\n",
    "# Gestion de la checkbox SHAP via session state\n",
    "st.session_state.show_shap = st.sidebar.checkbox(\n",
    "    \"Afficher l'explication SHAP\",\n",
    "    value=st.session_state.get(\"show_shap\", False)  # Utiliser .get() avec valeur par d√©faut\n",
    ")\n",
    "\n",
    "# === Initialisation de session state ===\n",
    "required_states = {\n",
    "    \"predicted\": False,\n",
    "    \"client_data\": None,\n",
    "    \"score_float\": None,\n",
    "    \"previous_id\": None,\n",
    "    \"client_row\": None,\n",
    "    \"show_shap\": False  # <-- Ajouter cette ligne\n",
    "}\n",
    "\n",
    "for key, value in required_states.items():\n",
    "    if key not in st.session_state:\n",
    "        st.session_state[key] = value\n",
    "\n",
    "# ===== R√©initialisation lors du changement d'ID =====\n",
    "if st.session_state.previous_id != selected_id:\n",
    "    for key in [\"predicted\", \"client_data\", \"score_float\", \"show_shap\"]:\n",
    "        st.session_state[key] = required_states[key]\n",
    "    # R√©initialiser l'√©tat d'animation\n",
    "    if 'current_animated_id' in st.session_state:\n",
    "        del st.session_state.current_animated_id\n",
    "    st.session_state.previous_id = selected_id\n",
    "\n",
    "\n",
    "# ===== Soumission pr√©diction =====\n",
    "if submitted:\n",
    "    client_row = df_test[df_test[\"SK_ID_CURR\"] == selected_id]\n",
    "    \n",
    "    if not client_row.empty:\n",
    "        try:\n",
    "            client_data = client_row.drop(columns=[\"SK_ID_CURR\"]).to_dict(orient=\"records\")[0]\n",
    "            response = requests.post(f\"{API_URL}/predict\", json={\"data\": client_data})\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            \n",
    "            # Mise √† jour session state\n",
    "            st.session_state.update({\n",
    "                \"score_float\": float(result['probability']) / 100,\n",
    "                \"client_data\": client_data,\n",
    "                \"client_row\": client_row,\n",
    "                \"predicted\": True\n",
    "            })\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            st.error(f\"Erreur lors de la pr√©diction : {e}\")\n",
    "            st.session_state.predicted = False\n",
    "    else:\n",
    "        st.error(\"Client introuvable dans les donn√©es\")\n",
    "        st.session_state.predicted = False\n",
    "\n",
    "# ===== Affichage des r√©sultats =====\n",
    "col_left, col_right = st.columns([1, 1])\n",
    "\n",
    "# Colonne gauche - Toujours visible\n",
    "with col_left:\n",
    "    st.subheader(\"üìã Infos Client\")\n",
    "    \n",
    "    # Fonctions de formatage\n",
    "    # Fonctions de formatage\n",
    "    def safe_get(row, col, default=\"N/A\"):\n",
    "        return row[col] if col in row and not pd.isna(row[col]) else default\n",
    "\n",
    "    def format_currency(value):\n",
    "        try:\n",
    "            return f\"{float(value):,.0f} ‚Ç¨\"\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "\n",
    "    def format_percentage(value):\n",
    "        try:\n",
    "            return f\"{float(value)*100:.1f} %\"\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "\n",
    "    def format_gender(value):\n",
    "        return {1: \"Homme\", 0: \"Femme\"}.get(value, \"Inconnu\")\n",
    "\n",
    "    def format_years(value):\n",
    "        try:\n",
    "            return f\"{-int(value)//365} ans\"\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "\n",
    "    # S√©lection d'une ligne par ID\n",
    "    row = df_test[df_test[\"SK_ID_CURR\"] == selected_id].iloc[0]\n",
    "\n",
    "    # Dictionnaire des infos format√©es\n",
    "    infos = {\n",
    "        \"ID Client\": int(row[\"SK_ID_CURR\"]),\n",
    "        \"√Çge\": format_years(safe_get(row, \"DAYS_BIRTH\")),\n",
    "        \"Genre\": format_gender(safe_get(row, \"CODE_GENDER\")),\n",
    "        \"Charge cr√©dit\": format_percentage(safe_get(row, \"INCOME_CREDIT_PERC\")),\n",
    "        \"Historique cr√©dit\": format_years(safe_get(row, \"BURO_DAYS_CREDIT_MEAN\"))\n",
    "    }\n",
    "\n",
    "    # Construction du DataFrame pour affichage\n",
    "    df_infos = pd.DataFrame(list(infos.items()), columns=[\"Libell√©\", \"Valeur\"])\n",
    "    df_infos[\"Valeur\"] = df_infos[\"Valeur\"].astype(str)  # üî• force explicite en string\n",
    "    #st.dataframe(df_infos)\n",
    "    AgGrid(df_infos, height=200, fit_columns_on_grid_load=True)\n",
    "\n",
    "    # --- Analyse SHAP Globale ---\n",
    "    # --- Analyse SHAP Globale ---\n",
    "    if st.session_state.predicted and st.session_state.show_shap:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Analyse Globale\")\n",
    "        with st.spinner(\"Calcul des tendances globales...\"):\n",
    "            try:\n",
    "                # Utilisation directe du summary plot\n",
    "                fig_global = plt.figure(figsize=(10, 6))\n",
    "                shap.summary_plot(\n",
    "                global_shap_values,\n",
    "                df_test_sample[features],\n",
    "                plot_type=\"bar\",\n",
    "                max_display=10,\n",
    "                show=False\n",
    "            )\n",
    "                plt.title(\"Top 10 - Impact Global des Variables\", pad=20)\n",
    "                st.pyplot(fig_global)\n",
    "                plt.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"Erreur analyse globale : {str(e)}\")\n",
    "# Colonne droite - R√©sultats pr√©diction\n",
    "with col_right:\n",
    "    #st.subheader(\"Analyse du risque client\")\n",
    "\n",
    "    if st.session_state.predicted:\n",
    "        try:\n",
    "            # --- 1. Gestion de l'animation ---\n",
    "            # R√©initialiser l'√©tat d'animation pour chaque nouvel ID\n",
    "            if 'current_animated_id' not in st.session_state:\n",
    "                st.session_state.current_animated_id = None\n",
    "            \n",
    "            if st.session_state.current_animated_id != selected_id:\n",
    "                animate_risk_gauge(\n",
    "                    score=st.session_state.score_float,\n",
    "                    client_id=selected_id\n",
    "                )\n",
    "                st.session_state.current_animated_id = selected_id\n",
    "            else:\n",
    "                # Affichage statique si m√™me client\n",
    "                show_risk_gauge(\n",
    "                    score=st.session_state.score_float, \n",
    "                    client_id=selected_id\n",
    "                )\n",
    "\n",
    "            # --- 2. Message d'alerte ---\n",
    "            display_risk_message(\n",
    "                score=st.session_state.score_float,\n",
    "                threshold=THRESHOLD\n",
    "            )\n",
    "            # --- 3. Explications SHAP ind√©pendantes ---\n",
    "            if st.session_state.show_shap:\n",
    "                st.markdown(\"---\")\n",
    "                with st.spinner(\"G√©n√©ration des explications SHAP...\"):\n",
    "                    X = pd.DataFrame([st.session_state.client_data])[features]\n",
    "                    X_scaled = pd.DataFrame(\n",
    "                        scaler.transform(X),\n",
    "                        columns=features,\n",
    "                        index=X.index\n",
    "                    )\n",
    "\n",
    "                    #shap_values = explainer(X_scaled)\n",
    "                    #fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    #shap.plots.bar(shap_values[0], max_display=10, show=False)\n",
    "                    #st.pyplot(fig)\n",
    "\n",
    "                    shap_values = explainer(X_scaled)\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    shap.plots.waterfall(shap_values[0], max_display=10, show=False)\n",
    "                    st.pyplot(fig)\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"Erreur d'affichage : {str(e)}\")\n",
    "    else:\n",
    "        show_risk_gauge(None, client_id=selected_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
