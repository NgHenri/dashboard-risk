# === Imports standards de Python ===
import os
import json
import logging
import warnings

# === Environnement ===
from dotenv import load_dotenv

# === Biblioth√®ques externes ===
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import shap
import requests
import joblib
from matplotlib import pyplot as plt

# === Modules internes ===
import config
from risk_gauge import show_risk_gauge, display_risk_message, animate_risk_gauge

# === Composants externes sp√©cifiques ===
from st_aggrid import AgGrid, JsCode, GridOptionsBuilder, GridUpdateMode

# === Utils : formatage & style ===
from utils.formatters import (
    safe_get,
    format_currency,
    format_percentage,
    format_gender,
    format_years,
)
from utils.styling import style_rules, build_dynamic_styling

# === Utils : interactions avec l'API ===
from utils.api_requests import (
    check_api_health,
    fetch_client_ids,
    fetch_client_info,
    fetch_prediction,
    fetch_population_stats,
)

# === Utils : SHAP & interpr√©tabilit√© ===
from utils.shap_utils import (
    fetch_client_data_for_shap,
    fetch_client_shap_data,
    fetch_global_shap_matrix,
    fetch_local_shap_explanation,
    fetch_batch_predictions,
)

# === Utils : interactions utilisateur ===
from utils.user_interactions import (
    prepare_client_info,
    create_interactive_grid,
    create_interactive_valeur_editor,
    build_feature_config,
    get_genre_client,
    get_updated_data,
    process_selection_and_display_plot,
)

# === Utils : visualisations ===
from utils.visuals import (
    plot_boxplot_comparison,
    plot_waterfall_chart_expandable,
    plot_summary_chart,
    get_title_font_size,
    plot_feature_distribution,
    restore_discrete_types,
    plot_feature_comparison,
    plot_client_position_in_group,
)

# ===== Param√®tres de configuration =====

load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "..", ".env"))
# load_dotenv()

API_URL = os.getenv("API_URL")
# print("üõ†Ô∏è API_URL:", API_URL)
API_KEY = os.getenv("API_KEY")


# warnings.filterwarnings("ignore", category=UserWarning)
# warnings.filterwarnings("ignore", category=FutureWarning)

# API_URL = "http://localhost:8000"  # URL de l'API backend
# API_KEY = "b678481b982dc71ab46e08255faefae5f73339c4f1339eec83edf10488502158"
ARTIFACT_PATH = "../backend/models/lightgbm_production_artifact_20250415_081218.pkl"  # Chemin vers l'artefact du mod√®le
THRESHOLD = 0.0931515  # Seuil de risque
TIMEOUT = 10  # Timeout pour les requ√™tes API (en secondes)
BATCH_SIZE = 200  # Taille des lots pour les pr√©dictions

# ===== V√©rification de la connexion API =====
# Fonction de v√©rification
# ===== V√©rification de la connexion API =====
check_result = check_api_health(TIMEOUT)
if check_result is not True:
    st.error(check_result)
    st.stop()

st.set_page_config(layout="wide")
st.title("üè¶ Dashboard Cr√©dit - Pr√©dictions & Explicabilit√©")


# ===== Chargement des donn√©es =====
# Fonction pour r√©cup√©rer les donn√©es de test depuis l'API
@st.cache_data
def load_test_data_from_api():
    """R√©cup√®re les donn√©es de test via l'API"""
    try:
        headers = {"x-api-key": API_KEY, "Accept": "application/json"}

        # Test de connexion basique
        health_response = requests.get(f"{API_URL}/health")
        if health_response.status_code != 200:
            st.error("L'API ne r√©pond pas correctement")
            return pd.DataFrame()

        # Requ√™te principale
        response = requests.get(
            f"{API_URL}/get_test_data", headers=headers, timeout=TIMEOUT
        )

        # Gestion sp√©cifique des erreurs 403
        if response.status_code == 403:
            st.error("Permission refus√©e - V√©rifiez la cl√© API")
            logger.error(f"Headers envoy√©s : {headers}")
            return pd.DataFrame()

        response.raise_for_status()

        return pd.DataFrame(response.json())

    except Exception as e:
        st.error(f"Erreur critique : {str(e)}")
        return pd.DataFrame()


# Chargement des donn√©es depuis l'API
df_test_raw = load_test_data_from_api()
df_test = restore_discrete_types(df_test_raw, max_cardinality=15, verbose=True)

# V√©rification si les donn√©es sont vides apr√®s chargement
if df_test.empty:
    st.error("Erreur lors du chargement des donn√©es depuis l'API")
    st.stop()


# ===== Chargement des artefacts du mod√®le =====
# Fonction pour charger le mod√®le et les artefacts associ√©s (scaler, explainer, etc.)
@st.cache_resource
def load_model_artifacts():
    artifacts = joblib.load(ARTIFACT_PATH)
    model = artifacts["model"]
    scaler = artifacts["scaler"]
    features = artifacts["metadata"]["features"]
    explainer = shap.TreeExplainer(model)

    # R√©cup√©ration des donn√©es via l'API pour SHAP global
    try:
        response = requests.get(
            f"{API_URL}/global_shap_sample",
            headers={"x-api-key": API_KEY},
            timeout=TIMEOUT,
        )
        response.raise_for_status()
        df_test_sample = pd.DataFrame(response.json())
    except Exception as e:
        st.error(f"Erreur API : {str(e)}")
        st.stop()

    # Calcul des SHAP values pour l'√©chantillon de test
    df_test_sample_scaled = scaler.transform(df_test_sample[features])
    global_shap_values = explainer.shap_values(df_test_sample_scaled)

    return model, scaler, features, explainer, global_shap_values, df_test_sample


# ===== Chargement des artefacts du mod√®le =====
model, scaler, features, explainer, global_shap_values, df_test_sample = (
    load_model_artifacts()
)

# =============================================================================
# üì¶ Initialisation et v√©rifications
# =============================================================================

# R√©cup√©ration des IDs clients
client_ids = fetch_client_ids()
if not client_ids:
    st.error("Aucun client disponible - V√©rifiez la connexion √† l'API")
    st.stop()

# =============================================================================
# üìë Interface principale (Tabs)
# =============================================================================
tab1, tab2, tab3 = st.tabs(["Pr√©diction", "Exploration", "Analyse & Recommandation"])

# =============================================================================
# üß≠ Barre lat√©rale (sidebar)
# =============================================================================
st.sidebar.markdown("## üîç Analyse d'un client")

# S√©lection du client
client_ids = sorted(client_ids)
selected_id = st.sidebar.selectbox("S√©lectionner un client", client_ids)
if not selected_id or not isinstance(selected_id, int):
    st.warning("Veuillez s√©lectionner un client valide")
    st.stop()

# Bouton de soumission
submitted = st.sidebar.button("Soumettre la pr√©diction")

# Gestion de la checkbox SHAP via session state
st.session_state.show_shap = st.sidebar.checkbox(
    "Afficher l'explication SHAP",
    value=st.session_state.get(
        "show_shap", False
    ),  # Utiliser .get() avec valeur par d√©faut
)

# Options suppl√©mentaires
st.markdown("---")
st.sidebar.markdown("## üîß Options")
compare_group = st.sidebar.radio(
    "Groupe de comparaison",
    ["Population totale", "Clients similaires"],
    help="S√©lectionnez le groupe de r√©f√©rence pour les comparaisons",
)

# Initialisation de session state (valeurs par d√©faut)
required_states = {
    "predicted": False,
    "client_data": None,
    "score_float": None,
    "previous_id": None,
    "client_row": None,
    "show_shap": False,  # <-- Ajouter cette ligne
}

for key, value in required_states.items():
    if key not in st.session_state:
        st.session_state[key] = value

# =============================================================================
# üîÅ R√©initialisation des donn√©es lors d‚Äôun changement de client
# =============================================================================
if st.session_state.previous_id != selected_id:
    for key in ["predicted", "client_data", "score_float", "show_shap"]:
        st.session_state[key] = required_states[key]

    # R√©initialiser l'√©tat d'animation s'il existe
    if "current_animated_id" in st.session_state:
        del st.session_state.current_animated_id

    st.session_state.previous_id = selected_id
    # IMPORTANT : R√©initialiser la grid pour charger les nouvelles infos client
    st.session_state.client_row = None

# Charger automatiquement le premier client au d√©marrage ou en cas de changement
if st.session_state.client_row is None:
    client_info = fetch_client_info(selected_id)
    if client_info:
        client_row = pd.DataFrame([client_info])
        st.session_state.client_row = client_row
        st.session_state.client_data = client_row.drop(columns=["SK_ID_CURR"]).to_dict(
            orient="records"
        )[0]

# =============================================================================
# üîÆ Soumission de la pr√©diction
# =============================================================================

if submitted:
    client_info = fetch_client_info(selected_id)
    if not client_info:
        st.error("Donn√©es client non disponibles")
        st.stop()

    # Conversion en DataFrame puis mise √† jour dans le session state
    client_row = pd.DataFrame([client_info])
    st.session_state.client_row = client_row
    st.session_state.client_data = client_row.drop(columns=["SK_ID_CURR"]).to_dict(
        orient="records"
    )[0]
    # ===
    if not client_row.empty:
        try:
            client_data = client_row.drop(columns=["SK_ID_CURR"]).to_dict(
                orient="records"
            )[0]

            # Appel de la fonction fetch_predictionn
            result = fetch_prediction(API_URL, client_data)

            # Mise √† jour session state
            st.session_state.update(
                {
                    "score_float": float(result["probability"]) / 100,
                    "client_data": client_data,
                    "client_row": client_row,
                    "predicted": True,
                }
            )

        except requests.exceptions.RequestException as e:
            st.error(f"Erreur lors de la pr√©diction : {e}")
            st.session_state.predicted = False
    else:
        st.error("Client introuvable dans les donn√©es")
        st.session_state.predicted = False

# with st.sidebar.expander("IDs des clientes", expanded=True):
#    female_ids = (
#        df_test[df_test["CODE_GENDER"] == 0]["SK_ID_CURR"].astype(int).sort_values()
#    )
#    st.write(female_ids.tolist())

# =============================================================================
# üìä Onglet 1 : Pr√©diction
# =============================================================================
with tab1:
    st.header("Info Client")

    # --- Container 1 - Grid et pr√©diction ---
    with st.container():
        col_left, col_right = st.columns(2)

        with col_left:
            # 1) R√©cup√©rer le client (d√©j√† stock√© dans st.session_state.client_row)
            client_info = fetch_client_info(selected_id)
            if client_info is None:
                st.error("Impossible de charger les infos client")
                st.stop()

            # 2) Pr√©parer ou r√©utiliser la grille selon l'ID
            if st.session_state.get("grid_for_id") != selected_id:
                # Nouvel ID ‚Üí (re)pr√©pare la grille
                df_infos = prepare_client_info(st.session_state.client_row.iloc[0])
                st.session_state.df_infos = df_infos
                st.session_state.grid_for_id = selected_id
            else:
                # M√™me ID ‚Üí r√©utilise l'ancienne grille
                df_infos = st.session_state.df_infos

            # 3) Afficher la grille (avec key unique)
            updated_df, grid_response = create_interactive_grid(
                df_infos,
                edit=False,
                context=f"prediction_{selected_id}",
            )

            # 4) Construire la config des features
            feature_config = build_feature_config()

            # Traitement des s√©lections
            genre_client = get_genre_client(updated_df)
            updated_data = get_updated_data(updated_df, feature_config)

            # Pour chaque feature affich√©e par l'utilisateur
            process_selection_and_display_plot(
                grid_response,
                feature_config,
                genre_client,
                compare_group,
                API_URL,
                API_KEY,
            )
        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üìà Partie droite : Affichage du score + jauge ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with col_right:
            st.subheader("Affichage pr√©diction")
            if st.session_state.predicted:
                try:
                    if "current_animated_id" not in st.session_state:
                        st.session_state.current_animated_id = None

                    if st.session_state.current_animated_id != selected_id:
                        animate_risk_gauge(
                            score=st.session_state.score_float, client_id=selected_id
                        )
                        st.session_state.current_animated_id = selected_id
                    else:
                        show_risk_gauge(
                            score=st.session_state.score_float, client_id=selected_id
                        )

                    display_risk_message(
                        score=st.session_state.score_float, threshold=THRESHOLD
                    )

                except Exception as e:
                    st.error(f"Erreur affichage pr√©diction : {str(e)}")
            else:
                show_risk_gauge(None, client_id=selected_id)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üîç Partie inf√©rieure : Analyse globale et locale ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    with st.container():
        col_global, col_local = st.columns(2)

        with col_global:
            with st.expander("üìñ Analyse Globale"):
                # --- Analyse SHAP Globale ---
                if st.session_state.predicted and st.session_state.show_shap:
                    st.markdown("---")
                    with st.spinner("Calcul des tendances globales..."):
                        try:
                            # R√©cup√©ration des donn√©es via le cache
                            data = fetch_global_shap_matrix(sample_size=1000)

                            # Conversion des donn√©es
                            shap_values = np.array(data["shap_values"])
                            feature_values = pd.DataFrame(data["feature_values"])
                            features = data["features"]  # Extraction depuis metadata
                            base_value = data["base_value"]

                            # Cr√©ation d'un array de base_values adapt√©
                            n_samples = shap_values.shape[0]
                            base_values = np.full(n_samples, base_value)

                            # Cr√©ation de la "structure" d'explication attendue par notre plot
                            explanation = {
                                "values": shap_values,
                                "data": feature_values.values,
                                "feature_names": features,
                            }

                            # G√©n√©ration du summary plot avec Plotly
                            fig = plot_summary_chart(explanation, max_display=10)
                            st.plotly_chart(fig, use_container_width=True)

                            # Streamlit UI
                            selected_id = st.session_state.previous_id

                        except Exception as e:
                            st.error(f"Erreur lors de l'analyse SHAP : {str(e)}")
                            st.stop()

                            st.markdown(
                                '<div class="feature-card">', unsafe_allow_html=True
                            )
                            st.subheader("üìñ Explication du score")
                            with st.spinner("G√©n√©ration des explications SHAP..."):
                                try:
                                    explanation = fetch_local_shap_explanation(
                                        selected_id
                                    )

                                    fig = plot_waterfall_chart_expandable(explanation)
                                except Exception as e:
                                    st.error(f"Erreur technique : {str(e)}")
                            st.markdown("</div>", unsafe_allow_html=True)
        # ===========================
        # --- ANALYSE LOCALE (SHAP)
        # ===========================
        with col_local:
            st.subheader("Analyse locale")
            if st.session_state.show_shap:  # V√©rifier uniquement show_shap
                if st.session_state.predicted:
                    with st.spinner("G√©n√©ration des explications SHAP..."):
                        try:
                            explanation = fetch_local_shap_explanation(selected_id)
                            if explanation:  # V√©rifier que les donn√©es sont valides
                                plot_waterfall_chart_expandable(explanation)
                            else:
                                st.warning("Donn√©es SHAP non disponibles")
                        except Exception as e:
                            st.error(f"Erreur technique : {str(e)}")
                else:
                    st.info("Soumettre la pr√©diction pour voir l'analyse")
            else:
                st.info(
                    "Cochez 'Afficher l'explication SHAP' pour voir l'analyse locale"
                )
    # ====================================================
    # --- ANALYSE SHAP - Visualisation des distributions
    # ====================================================
    # --- Container 3  ---
    with st.container():
        if st.session_state.predicted and st.session_state.show_shap:
            # if st.session_state.show_shap:
            st.markdown("---")

            # R√©cup√©ration des valeurs SHAP
            explanation = fetch_local_shap_explanation(selected_id)

            with st.container():
                col_viz1, col_viz2 = st.columns(2)

                # Construction du DataFrame SHAP
                shap_values_df = pd.DataFrame(
                    {
                        "feature": explanation["features"],
                        "shap_value": explanation["values"],
                        "feature_value": list(explanation["client_data"].values()),
                        "SK_ID_CURR": selected_id,
                    }
                ).sort_values(by="shap_value", ascending=False)

                # Top 15 features contribuant positivement et n√©gativement
                top_15_positive = shap_values_df.head(15)
                top_15_negative = shap_values_df.tail(15).sort_values(by="shap_value")

                selected_pos_feature = col_viz1.selectbox(
                    "üìà Variable augmentant le risque (Top 15)",
                    top_15_positive["feature"],
                    key="pos_feature",
                )

                selected_neg_feature = col_viz2.selectbox(
                    "üìâ Variable r√©duisant le risque (Top 15)",
                    top_15_negative["feature"],
                    key="neg_feature",
                )

            with st.container():
                col_viz1, col_viz2 = st.columns(2)

            # Chargement des donn√©es client
            client_df = pd.DataFrame([client_info])
            client_df_visu = restore_discrete_types(client_df)
            client_visu = client_df_visu.iloc[0]

            # Affichage des graphiques de distribution SHAP
            with col_viz1:
                st.subheader("Graphique SHAP 1")
                dist1 = plot_feature_distribution(
                    feature_name=selected_pos_feature,
                    full_data=df_test,
                    client_data=client_visu,
                    base_color="crimson",
                    client_bin_color="yellow",
                    title_prefix="üìà Risque ‚Üë",
                )
                st.plotly_chart(dist1, use_container_width=True)

            with col_viz2:
                st.subheader("Graphique SHAP 2")
                dist2 = plot_feature_distribution(
                    feature_name=selected_neg_feature,
                    full_data=df_test,
                    client_data=client_visu,
                    base_color="seagreen",
                    client_bin_color="yellow",
                    title_prefix="üìâ Risque ‚Üì",
                )
                st.plotly_chart(dist2, use_container_width=True)

# ========================
# --- TAB 2 : EXPLORATION
# ========================
with tab2:
    st.header("Exploration")
    feature_config = build_feature_config()

    # Container 1 - Grid √©ditable et boxplots
    with st.container():
        col_left, col_right = st.columns(2)

        with col_left:
            st.subheader("Info Client")
            if st.session_state.client_row is not None:
                df_infos = prepare_client_info(st.session_state.client_row.iloc[0])
                updated_df, grid_response = create_interactive_grid(
                    df_infos, edit=True, context=f"exploration_{selected_id}"
                )
            else:
                st.warning("Aucune donn√©e client disponible")
                st.stop()

            # V√©rification suppl√©mentaire
            if "updated_df" not in locals():
                st.error("Erreur de chargement des donn√©es client")
                st.stop()

            # Traitement des s√©lections
            genre_client = get_genre_client(updated_df) or 0  # Valeur par d√©faut
            updated_data = get_updated_data(updated_df, feature_config)

        with col_right:
            st.subheader("Illustration")
            if genre_client is not None:
                process_selection_and_display_plot(
                    grid_response,
                    feature_config,
                    genre_client,
                    compare_group,
                    API_URL,
                    API_KEY,
                    show_empty_info=True,
                )
            else:
                st.warning("Configuration du genre client non disponible")


# ===================================
# --- FUNCTION : BATCH SIMULATION
# ===================================
@st.cache_data(show_spinner="Chargement des pr√©dictions batch...", ttl=600)
def simulate_batch(
    df_clients: pd.DataFrame, filter_decision: str = None
) -> pd.DataFrame:
    res = fetch_batch_predictions(df_clients, filter_decision)
    res["SK_ID_CURR"] = res["SK_ID_CURR"].astype(int)
    return res


# ========================
# --- TAB 3 : SIMULATION
# ========================
with tab3:
    st.header("üìà Analyse & Recommandation")
    # 1) Edit client dataset
    st.subheader("üîç √âditer info Client")
    df = df_test.copy()
    tab_analyse, tab_recommandation = st.tabs(["Analyse", "Recommandation"])

    # --- ANALYSE GUID√âE / LIBRE ---
    with tab_analyse:
        st.header("Analyse exploratoire")
        sub_guided, sub_custom = st.tabs(["1Ô∏è‚É£ Guid√©e", "2Ô∏è‚É£ Personnalis√©e"])
        with sub_guided:
            FEATURE_PAIRS = {
                "Stabilit√© vs Capacit√© remb.": (
                    "DAYS_EMPLOYED_PERC",
                    "INCOME_CREDIT_PERC",
                ),
                "Anciennet√© vs Montant cr√©dit": (
                    "DAYS_EMPLOYED_PERC",
                    "AMT_CREDIT",
                ),
                "Montant cr√©dit vs Charge mens.": (
                    "AMT_CREDIT",
                    "ANNUITY_INCOME_PERC",
                ),
                "Montant cr√©dit vs Capacit√© remb.": (
                    "AMT_CREDIT",
                    "INCOME_CREDIT_PERC",
                ),
                "Retards cr√©dits pass√©s vs Capacit√© remb.": (
                    "BURO_AMT_CREDIT_MAX_OVERDUE_MEAN",
                    "INCOME_CREDIT_PERC",
                ),
                "Autres pr√™ts vs Montant cr√©dit": (
                    "BURO_CREDIT_TYPE_ANOTHER_TYPE_OF_LOAN_MEAN",
                    "AMT_CREDIT",
                ),
            }

            choice = st.selectbox("Paire de variables", list(FEATURE_PAIRS.keys()))
            fx, fy = FEATURE_PAIRS[choice]
            ptype = st.radio(
                "Type graphique",
                ["scatter", "histogram", "density", "histogram2d"],
                horizontal=True,
            )
            plot_feature_comparison(df, fx, fy, ptype)
        with sub_custom:
            numeric = df.select_dtypes("number").columns.tolist()
            cx = st.selectbox("Variable X", numeric)
            cy = st.selectbox("Variable Y", numeric)
            ctype = st.radio(
                "Type graphique", ["scatter", "histogram", "density"], horizontal=True
            )
            plot_feature_comparison(df, cx, cy, ctype)

    # --- RECOMMANDATION & SIMULATION BATCH ---
    with tab_recommandation:
        df_info = prepare_client_info(st.session_state.client_row.iloc[0])
        st.header("Recommandation et simulation batch")

        # √âtape 1 : √âdition des infos
        st.subheader("1Ô∏è‚É£ √âditer le dataset du client")
        df_editable, grid_opts = create_interactive_valeur_editor(
            df_info, edit=True, context=f"editor_{selected_id}"
        )

        # √âtape 2 : Param√®tres de simulation
        st.subheader("2Ô∏è‚É£ Param√®tres de simulation")
        decision_filter = st.selectbox(
            "Filtrer par d√©cision initiale:", ["Tous", "‚úÖ Accept√©", "‚ùå Refus√©"]
        )
        filter_val = None if decision_filter == "Tous" else decision_filter

        if st.button("üîÆ Lancer la simulation batch", key="run_tab3"):
            # -- R√©cup√®re la ligne du client s√©lectionn√© depuis le df d'origine
            selected_client_row = df[df["SK_ID_CURR"] == selected_id]

            # -- √âchantillonne le reste du batch (hors client s√©lectionn√©)
            df_remaining = df[df["SK_ID_CURR"] != selected_id]
            sample_df = df_remaining.sample(BATCH_SIZE - 1, random_state=42)

            # -- Ajoute le client s√©lectionn√© en premi√®re ligne
            sample_df = pd.concat([selected_client_row, sample_df], ignore_index=True)

            # -- Simulation
            df_results = simulate_batch(sample_df, filter_val)

            # -- Enregistre r√©sultats + ID s√©lectionn√©
            st.session_state["simul_results"] = df_results
            st.session_state["default_focus_id"] = selected_id
            st.success("Simulation termin√©e !")

        # √âtape 3 : Affichage r√©sultats
        st.subheader("3Ô∏è‚É£ R√©sultats de la simulation")
        if "simul_results" in st.session_state:
            res_df = st.session_state["simul_results"]
            default_id = st.session_state.get(
                "default_focus_id", res_df["SK_ID_CURR"].iloc[0]
            )
            client_choice = st.selectbox(
                "Client pour focus:",
                res_df["SK_ID_CURR"].tolist(),
                key="focus_tab3",
                index=res_df["SK_ID_CURR"].tolist().index(default_id),
            )

            st.dataframe(res_df[["SK_ID_CURR", "probability", "decision"]])
            plot_client_position_in_group(res_df, client_choice)
        else:
            st.info("Aucune simulation ex√©cut√©e. Cliquez sur le bouton ci-dessus.")
