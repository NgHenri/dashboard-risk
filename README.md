# ğŸ“Š Dashboard de scoring de risque de crÃ©dit - Projet "PrÃªt Ã  DÃ©penser"

## ğŸŒŸ Objectif du projet
Ce projet vise Ã  crÃ©er un outil d'aide Ã  la dÃ©cision pour les conseillers clientÃ¨le de l'organisme de prÃªt "PrÃªt Ã  dÃ©penser". L'objectif est d'Ã©valuer le risque qu'un client prÃ©sente un dÃ©faut de paiement afin d'aider Ã  l'acceptation ou au refus d'une demande de crÃ©dit. Le modÃ¨le tient compte du fait qu'un faux nÃ©gatif (accorder un crÃ©dit Ã  un mauvais payeur) est beaucoup plus coÃ»teux qu'un faux positif (refuser un bon payeur).

---

## ğŸ§  Approche Machine Learning

### ğŸ”„ DonnÃ©es
- Jeux de donnÃ©es : ğŸ”— [Home Credit Default Risk â€“ Home Credit Group](https://www.kaggle.com/c/home-credit-default-risk/data)
- Plus de **300 000 clients** avec 122 variables.
- Environ **8 %** de dÃ©fauts de paiement.

### ğŸ§¬ PrÃ©traitement et Feature Engineering
Une grande partie de lâ€™inspiration pour lâ€™ingÃ©nierie des features et lâ€™approche LightGBM provient de ce notebook Kaggle :  
ğŸ”— [LightGBM with Simple Features â€“ jsaguiar](https://www.kaggle.com/code/jsaguiar/lightgbm-with-simple-features)
ğŸ”— [6 Ways for Feature Selection â€“ sz8416](https://www.kaggle.com/code/sz8416/6-ways-for-feature-selection)
- Nettoyage des donnÃ©es (valeurs aberrantes, outliers)
- LabelEncoding / OneHotEncoding des variables catÃ©gorielles
- AgrÃ©gations et crÃ©ation de nouvelles variables (ratios, diffÃ©rences, etc.)
- Normalisation et gestion des valeurs manquantes
- Feature selection

### ğŸ“Š ModÃ¨les testÃ©s
- DummyClassifier (baseline)
- Logistic Regression
- RandomForest
- Gradient Boosting
- XGBoost
- **LightGBM** (meilleur modÃ¨le)

### âš–ï¸ Optimisation
- **MÃ©triques classiques** : AUC ROC, Accuracy, Recall, F1.
- **Score mÃ©tier personnalisÃ©** : `10 Ã— FN + 1 Ã— FP`, minimisÃ© lors de lâ€™optimisation du seuil.
- **Optimisation du seuil** via Stratified K-Fold (5 folds) : seuil optimal par fold, seuil final = moyenne des seuils optimaux.
- Pipeline encapsulÃ© : SMOTE (train only, sampling_strategy=0.5) â†’ StandardScaler â†’ ModÃ¨le.


---

## ğŸ“ˆ Tracking & ExpÃ©rimentation avec MLflow
- Enregistrement de tous les runs : hyperparamÃ¨tres, mÃ©triques, temps dâ€™exÃ©cution.
- `input_example` et `signature` pour chaque modÃ¨le loguÃ©.
- Enregistrement du meilleur modÃ¨le comme **Registered Model**.
- Fonction gÃ©nÃ©rique `run_single_model()` ou `log_to_mlflow()` pour automatiser le tracking.

---
## ğŸ‰ RÃ©sultats
- ModÃ¨le final : **LightGBM + seuil optimisÃ©**
- AUC ROC : 0.79+, Score mÃ©tier : ~0.47 (sur jeu test)
- InterprÃ©tabilitÃ© intÃ©grÃ©e + pipeline complet enregistrÃ©

---

## ğŸ” ExplicabilitÃ©
- **SHAP Values** : explicabilitÃ© locale et globale.
- Visualisations intÃ©grÃ©es dans le dashboard Streamlit (force plots, bar plots, etc.).
- PrÃ©sentation claire des variables influentes pour chaque client.

---

## ğŸ¤– Analyse de la robustesse et du Data Drift
- Utilisation de **Evidently AI** pour comparer distributions entre train et production (ou jeu test simulant prod).
- **RÃ©sultat** : dÃ©rive dÃ©tectÃ©e sur 8 colonnes sur 105 (~â€¯7,6â€¯%), distances normalisÃ©es toutes <â€¯0,36 (seuil critique non atteint).  
  - Colonnes principalement financiÃ¨res ou dâ€™interaction client impactÃ©es (ex. AMT_CREDIT, AMT_ANNUITY, DAYS_LAST_PHONE_CHANGEâ€¦).
- **Conclusion** : pas de rÃ©entraÃ®nement urgent, mais surveillance continue conseillÃ©e sur ces variables sensibles.

---

## ğŸš€ DÃ©ploiement

### ğŸš§ Backend (API FastAPI)
- Endpoint `/predict` prenant en entrÃ©e les features validÃ©es par Pydantic, renvoyant probabilitÃ© et dÃ©cision selon seuil.
- Endpoint `/explain` renvoyant valeurs SHAP.
- Chargement des artefacts (scaler, modÃ¨le, seuil) depuis joblib
- Containerisation via `Dockerfile.backend`, dÃ©ploiement sur Render (ou autre).


##### ğŸ‘ï¸ Frontend (Streamlit)
- Application Streamlit :  
  - Saisie/chargement dâ€™un client (ID ou saisie manuelle des features).  
  - Affichage du score, de la dÃ©cision (AccordÃ©/RefusÃ©).  
  - Visualisation explicative (SHAP).  
  - Comparaison avec population ou segments.  
- Configuration via `config.py` (URL API, seuil, etc.).  
- Containerisation via `Dockerfile.frontend`, dÃ©ploiement sur Render.

### ğŸ§ª CI/CD & Tests
- **Tests unitaires** avec `pytest` pour modules ML, utilitaires, et endpoints FastAPI (TestClient).  
- Rapport de couverture gÃ©nÃ©rÃ© (`coverage run -m pytest` + `coverage html`) -> dossier `htmlcov/`.  
- **GitHub Actions** : 
  - CI : installation, lint, tests, gÃ©nÃ©ration du rapport coverage (artefact).  
  - CD : build des images Docker et dÃ©ploiement automatique sur Render.

### ğŸ“Š MLOps
- Suivi des runs via MLflow, stockage centralisÃ© des artefacts.
- Monitoring en production : intÃ©grer mÃ©triques de latence, erreurs, et indicateurs de drift.
- Versioning du modÃ¨le et automatisation du re-dÃ©ploiement lors dâ€™un nouveau run validÃ©.



---
## ğŸ§© Vue dâ€™ensemble
```mermaid
flowchart LR
    A["Donnees clients (Kaggle)"] --> B[Pretraitement et Feature Engineering]
    B --> C[Modelisation LightGBM et seuil optimise]
    C --> D[Tracking avec MLflow et sauvegarde]
    D --> E["Deploiement API (FastAPI)"]
    E --> F["Dashboard (Streamlit)"]
    F --> G["Utilisateur metier (Conseiller credit)"]

    subgraph Developpement
        B
        C
        D
    end

    subgraph Production
        E
        F
    end
```


## ğŸ“‚ Structure du projet
```
dashboard-risk/
â”œâ”€â”€ backend/           # API FastAPI, modÃ¨les et outils
â”œâ”€â”€ frontend/          # Interface utilisateur Streamlit
â”œâ”€â”€ assets/            # CSS et ressources
â”œâ”€â”€ notebooks/         # Exploration et notebooks de travail
â”œâ”€â”€ tests/             # Tests unitaires
â”œâ”€â”€ requirements.txt   # DÃ©pendances backend
â”œâ”€â”€ environment.yml    # Environnement complet
â””â”€â”€ README.md
```

---

## ğŸ”§ Installation rapide
```bash
# 1. Cloner le projet
git clone https://github.com/NgHenri/dashboard-risk.git
cd dashboard-risk

# 2. CrÃ©er un environnement conda
conda env create -f environment.yml
conda activate dashboard-risk

# 3. Installer dÃ©pendances spÃ©cifiques si besoin
pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt

# 4. Lancer les tests de couverture
pytest
coverage run -m pytest
coverage html   # gÃ©nÃ©rera ou mettra Ã  jour htmlcov/

# 5. DÃ©marrer lâ€™API
cd backend
uvicorn main:app --reload --port 8000

# 6. DÃ©marrer le dashboard
streamlit run frontend/app.py
```
---
## ğŸš€ DÃ©ploiement

#### A.Fast-API
- L'API FastAPI peut Ãªtre dÃ©ployÃ©e dans un conteneur Docker lÃ©ger. Deux options sont proposÃ©es selon ton environnement d'hÃ©bergement
- -  ğŸ”§ Option 1 : DÃ©ploiement standard avec ğŸ³ Dockerfile.backend
- - - Utilisation classique pour un environnement local ou un serveur Docker standard.

##### ğŸ§ª Build & ExÃ©cution locale

```bash
docker build -f Dockerfile.backend -t fastapi-backend .
docker run -p 8000:8000 fastapi-backend

```
- - â˜ï¸ Option 2 : DÃ©ploiement sur Railway, Render ou Fly.io avec entrypoint.sh
```bash
docker build -f Dockerfile.backend -t fastapi-backend .
docker run -e PORT=10000 -p 10000:10000 fastapi-backend

```

Cette version est mieux adaptÃ©e aux plateformes cloud qui imposent une variable dâ€™environnement PORT.

#### B. Streamlit

- L'application frontend est construite avec Streamlit. Elle peut Ãªtre conteneurisÃ©e et dÃ©ployÃ©e via Docker Ã  l'aide d'une image lÃ©gÃ¨re.

- - DÃ©ploiement standard avec ğŸ³ Dockerfile.frontend
Utilisation classique pour un environnement local ou un serveur Docker standard.

##### ğŸ§ª Build & ExÃ©cution locale
```bash
docker build -f Dockerfile.frontend -t streamlit-frontend .
docker run -p 8501:8501 streamlit-frontend
```
Une fois lancÃ©, lâ€™application sera accessible Ã  l'adresse suivante :

```http
http://localhost:8501
```

## ğŸ§­ Vue d'ensemble de l'application
```mermaid
flowchart TD
    A["Utilisateur (navigateur)"] --> B[Application Streamlit]
    B --> C[Chargement des donnÃ©es client]
    B --> D[Appel Ã  l'API FastAPI]
    D --> E[Renvoie la prÃ©diction et les explications SHAP]
    B --> F[Affichage : Score, Shap, Interactions]
```


## ğŸ§­ Prochaines Ã©tapes possibles

    âœ… Mettre en place un reverse proxy (ex: NGINX) pour rÃ©partir les requÃªtes entre plusieurs instances backend.

    âœ… IntÃ©grer un systÃ¨me dâ€™authentification par API Key dans NGINX ou au niveau de lâ€™API FastAPI.

    ğŸ”„ ImplÃ©menter la gestion de sessions utilisateurs (clÃ© unique/token).
  -  Authentification et architecture avec NGINX
  ```mermaid
  flowchart TD
      U[Utilisateur] -->|RequÃªte HTTP avec API Key| N[Serveur NGINX]

      subgraph Backend
          B1[FastAPI Backend #1]
          B2[FastAPI Backend #2]
      end

      N -->|Routage intelligent| B1
      N --> B2

      B1 -->|RÃ©ponse JSON| N
      B2 --> N
      N -->|DonnÃ©es traitÃ©es| F[Frontend Streamlit]

      F -->|Affichage Score, SHAP, etc.| U
  ```

    ğŸ“ˆ Ajouter un systÃ¨me de monitoring :



        Pour les donnÃ©es : Evidently

        Pour lâ€™infrastructure : Prometheus + Grafana

---


Pour toute question ou amÃ©lioration, n'hÃ©sitez pas Ã  me contacter !

[![Model](https://img.shields.io/badge/LightGBM-0.7985_AUC-blue)](https://lightgbm.readthedocs.io/)

