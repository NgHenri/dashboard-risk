## ğŸ“ **Description du projet â€” Scoring client pour "PrÃªt Ã  dÃ©penser"**

L'organisme de prÃªt *"PrÃªt Ã  dÃ©penser"* souhaite fournir Ã  ses **conseillers clientÃ¨le** un outil d'aide Ã  la dÃ©cision leur permettant d'Ã©valuer le risque de dÃ©faut dâ€™un client avant lâ€™octroi dâ€™un prÃªt.

### ğŸ¯ Objectif
DÃ©velopper un **modÃ¨le de scoring fiable, explicable et intÃ©grÃ© dans une application web** (via une API) permettant dâ€™estimer, Ã  partir des informations dâ€™un client, sâ€™il existe un **risque suffisant dâ€™insolvabilitÃ©** pour refuser un prÃªt.

Une **contrainte mÃ©tier forte** est imposÃ©e :  
> Le **coÃ»t dâ€™un prÃªt accordÃ© Ã  un mauvais payeur est 10 fois (voire 100 fois) plus Ã©levÃ©** que celui dâ€™un refus injustifiÃ©.

---

## ğŸ“Š DonnÃ©es

- **Jeu dâ€™entraÃ®nement** : 307 511 clients, 122 variables
- **Variable cible** : dÃ©faut de paiement (environ 8% de dÃ©fauts â†’ donnÃ©es dÃ©sÃ©quilibrÃ©es)
- **Jeu de production** : 50 000 nouveaux clients, avec donnÃ©es prÃ©remplies

---

## ğŸ”§ Feature engineering

Les transformations sont inspirÃ©es des meilleures pratiques du domaine (notamment les notebooks de rÃ©fÃ©rence sur Kaggle) :

- Suppression d'outliers
- Regroupement et transformation de jeux de donnÃ©es secondaires (bureau, previous_application, POS, etc.)
- Encodage : Label Encoding / One-hot Encoding
- CrÃ©ation de nouvelles variables (ratios, diffÃ©rences de jours, scores normalisÃ©s)
- Traitement du dÃ©sÃ©quilibre : **SMOTE**, **class_weight**, ou **undersampling**
- Nettoyage des colonnes et traitement des valeurs aberrantes

---

## ğŸ¤– ModÃ©lisation & suivi MLflow

### ğŸ“š ModÃ¨les testÃ©s :

- `DummyClassifier` (baseline)
- `LogisticRegression`
- `RandomForestClassifier`
- `XGBoostClassifier`
- `GradientBoostingClassifier`
- **`LightGBMClassifier` (modÃ¨le final)**

Chaque modÃ¨le a Ã©tÃ© :

- EntraÃ®nÃ© avec **validation croisÃ©e**
- Suivi avec **MLflow** (enregistrement des hyperparamÃ¨tres, mÃ©triques, durÃ©e dâ€™entraÃ®nement, artefacts)
- Ã‰valuÃ© avec des mÃ©triques classiques (**AUC, Accuracy, Recall, Confusion matrix**) mais aussi :
  - Un **score mÃ©tier personnalisÃ©**, prenant en compte le **coÃ»t diffÃ©rentiel entre faux positifs et faux nÃ©gatifs**
  - Une **optimisation du seuil de dÃ©cision** (proba) pour **minimiser ce score mÃ©tier**

ğŸ’¡ Le **modÃ¨le LightGBM**, avec `class_weight` et seuil optimisÃ©, a offert **le meilleur compromis performance/coÃ»t mÃ©tier/rapiditÃ©**.

---

## ğŸ“¦ Packaging du pipeline

Un pipeline complet a Ã©tÃ© mis en place, incluant :

- Imputation des valeurs manquantes
- Normalisation / standardisation si nÃ©cessaire
- ModÃ¨le LightGBM final
- Enregistrement via `joblib` et MLflow
- Chargement dynamique dans lâ€™API FastAPI

---

## ğŸ” ExplicabilitÃ©

- **Globale** : SHAP importance plot
- **Locale** : SHAP values pour un client donnÃ©, affichÃ©es dans le dashboard
- Ajout dâ€™un score lisible pour le conseiller : risque faible / moyen / Ã©levÃ©

---

## ğŸ“ˆ Analyse du Data Drift

- Analyse menÃ©e avec **Evidently**
- Comparaison entre jeux `train_samp` et `test_samp`
- 35% des variables prÃ©sentent un drift (ex. : `DAYS_BIRTH`, `EMPLOYED_TO_AGE_RATIO`, etc.)
- Ces dÃ©rives sont Ã  surveiller rÃ©guliÃ¨rement en production pour maintenir la robustesse du modÃ¨le

---

## ğŸŒ Architecture logicielle

- **Backend** (FastAPI) :
  - Endpoint `/predict` : score + SHAP
  - Endpoint `/health` : monitoring complet du systÃ¨me
- **Frontend** (Streamlit) :
  - Dashboard dynamique interrogeant uniquement lâ€™API
  - Aucun modÃ¨le local ni base de donnÃ©es stockÃ©e
- **DÃ©ploiement** :
  - PrÃªt pour un environnement **CI/CD**
  - IntÃ©gration continue facilitÃ©e avec versionnement du modÃ¨le via MLflow

---

## âœ… RÃ©sultat

Le systÃ¨me final permet aux conseillers dâ€™obtenir :

- Un **score de risque** clair
- Une **explication de la dÃ©cision**
- Un **processus fiable et automatisÃ©**, intÃ©grable dans leur environnement mÃ©tier


## ğŸ“‚ Structure du projet
dashboard-risk 
.
â”œâ”€â”€ README.md
â”œâ”€â”€ assets
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â”œâ”€â”€ test_1000_sample_for_api.csv
â”‚   â”‚   â”œâ”€â”€ test_1000_sample_with_target.csv
â”‚   â”‚   â”œâ”€â”€ test_2000_sample_for_api.csv
â”‚   â”‚   â”œâ”€â”€ test_2000_sample_with_target.csv
â”‚   â”‚   â”œâ”€â”€ test_500_sample_for_api.csv
â”‚   â”‚   â””â”€â”€ test_500_sample_with_target.csv
â”‚   â”œâ”€â”€ generate_api_key.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ inference_pipeline_20250413_17.joblib
â”‚   â”‚   â””â”€â”€ lightgbm_production_artifact_20250415_081218.pkl
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ tests
â”‚   â”‚   â”œâ”€â”€ test_config.py
â”‚   â”‚   â””â”€â”€ test_sanity.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ environment.yml
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ assets
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ risk_gauge.py
â”‚   â”œâ”€â”€ static
â”‚   â”œâ”€â”€ testsâ”‚   
â”‚   â”‚   â””â”€â”€ test_project
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ api_requests.py
â”‚       â”œâ”€â”€ formatters.py
â”‚       â”œâ”€â”€ shap_utils.py
â”‚       â”œâ”€â”€ styling.py
â”‚       â”œâ”€â”€ user_interactions.py
â”‚       â””â”€â”€ visuals.py
â”œâ”€â”€ git_push.sh
â”œâ”€â”€ htmlcov
â”‚   
â”œâ”€â”€ install_rclone.sh
â”œâ”€â”€ notebooks
â”‚   â””â”€â”€ tmp.ipynb
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ report.html
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.cfg
â””â”€â”€ sync_to_drive.sh
